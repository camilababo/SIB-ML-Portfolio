{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 12: Neural Networks and Backpropagation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from si.io.data_file import read_data_file\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from si.io.csv import read_csv\n",
    "from si.metrics.cross_entropy import cross_entropy\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.neural_networks.layers import Dense, ReLUActivation, LinearActivation, SigmoidActivation, SoftMaxActivation\n",
    "from si.neural_networks.nn import NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 12.1: Implement the backward propagation method for the ReLUActivation layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def backward(input_data: np.ndarray, error: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the backwards pass of the rectified linear relationship.\n",
    "    :return: Returns the error of the previous layer.\n",
    "    \"\"\"\n",
    "\n",
    "    relu_derivative = np.where(input_data > 0, 1, 0)\n",
    "\n",
    "    error_to_propagate = error * relu_derivative\n",
    "\n",
    "    return error_to_propagate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 12.2: Build a NN model for the breast-bin.csv dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "breast_bin_dataset = r\"C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\datasets\\breast-bin.data\"\n",
    "bb_dataset = read_data_file(breast_bin_dataset, sep=\",\", label=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "bb_dataset.x = StandardScaler().fit_transform(bb_dataset.x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bb_train, bb_test = train_test_split(bb_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(490, 9)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_train.shape()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "bb_layer1 = Dense(input_size=9, output_size=9)\n",
    "bb_layer2 = Dense(input_size=9, output_size=5)\n",
    "bb_layer3 = Dense(input_size=5, output_size=1)\n",
    "\n",
    "bb_layer1_activation = ReLUActivation()\n",
    "bb_layer2_activation = ReLUActivation()\n",
    "bb_layer3_activation = SigmoidActivation()\n",
    "\n",
    "bb_model = NN(\n",
    "    layers=[bb_layer1, bb_layer1_activation, bb_layer2, bb_layer2_activation, bb_layer3, bb_layer3_activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x16520f0e080>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_model.fit(dataset=bb_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5       ],\n       [0.50000026],\n       [0.50000007],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000154],\n       [0.50000182],\n       [0.50000029],\n       [0.50000029],\n       [0.50000014],\n       [0.50000003],\n       [0.5       ],\n       [0.50000012],\n       [0.50000457],\n       [0.5000001 ],\n       [0.50000238],\n       [0.5000001 ],\n       [0.50000001],\n       [0.50000008],\n       [0.50000003],\n       [0.50000011],\n       [0.50000014],\n       [0.50000017],\n       [0.50000017],\n       [0.50000009],\n       [0.50000046],\n       [0.50000008],\n       [0.50000082],\n       [0.50000008],\n       [0.50000135],\n       [0.50000003],\n       [0.50000009],\n       [0.5000002 ],\n       [0.50000008],\n       [0.50000088],\n       [0.5       ],\n       [0.50000001],\n       [0.50000075],\n       [0.50000001],\n       [0.50000012],\n       [0.5000001 ],\n       [0.50000064],\n       [0.50000014],\n       [0.50000038],\n       [0.50000001],\n       [0.50000076],\n       [0.50000043],\n       [0.50000187],\n       [0.50000064],\n       [0.50000062],\n       [0.50000007],\n       [0.50000004],\n       [0.50000031],\n       [0.50000007],\n       [0.50000001],\n       [0.50000056],\n       [0.50000013],\n       [0.50000002],\n       [0.50000064],\n       [0.50000011],\n       [0.50000011],\n       [0.5000001 ],\n       [0.50000008],\n       [0.50000067],\n       [0.50000302],\n       [0.50000044],\n       [0.50000119],\n       [0.50000011],\n       [0.5       ],\n       [0.5       ],\n       [0.5000001 ],\n       [0.50000005],\n       [0.50000072],\n       [0.50000014],\n       [0.50000106],\n       [0.50000005],\n       [0.50000014],\n       [0.5000002 ],\n       [0.50000062],\n       [0.50000001],\n       [0.50000083],\n       [0.5       ],\n       [0.50000016],\n       [0.50000184],\n       [0.50000004],\n       [0.50000001],\n       [0.5       ],\n       [0.50000087],\n       [0.50000024],\n       [0.50000035],\n       [0.50000008],\n       [0.50000007],\n       [0.50000006],\n       [0.50000074],\n       [0.50000007],\n       [0.50000031],\n       [0.50000001],\n       [0.50000001],\n       [0.50000107],\n       [0.50000023],\n       [0.50000004],\n       [0.5000005 ],\n       [0.50000008],\n       [0.50000001],\n       [0.5       ],\n       [0.50000015],\n       [0.50000004],\n       [0.50000072],\n       [0.5000006 ],\n       [0.50000008],\n       [0.50000004],\n       [0.50000067],\n       [0.50000038],\n       [0.5       ],\n       [0.50000004],\n       [0.50000081],\n       [0.50000005],\n       [0.50000007],\n       [0.5       ],\n       [0.50000003],\n       [0.50000043],\n       [0.50000008],\n       [0.50000005],\n       [0.50000009],\n       [0.5       ],\n       [0.50000025],\n       [0.50000014],\n       [0.50000008],\n       [0.50000047],\n       [0.50000055],\n       [0.50000011],\n       [0.5       ],\n       [0.50000056],\n       [0.50000135],\n       [0.50000032],\n       [0.50000014],\n       [0.50000014],\n       [0.5       ],\n       [0.50000017],\n       [0.5       ],\n       [0.50000011],\n       [0.50000012],\n       [0.5000001 ],\n       [0.5       ],\n       [0.50000004],\n       [0.5       ],\n       [0.50000178],\n       [0.50000011],\n       [0.50000077],\n       [0.50000019],\n       [0.50000065],\n       [0.50000008],\n       [0.50000031],\n       [0.50000006],\n       [0.50000043],\n       [0.50000007],\n       [0.50000026],\n       [0.50000104],\n       [0.50000149],\n       [0.50000004],\n       [0.50000001],\n       [0.50000138],\n       [0.50000008],\n       [0.50000023],\n       [0.50000013],\n       [0.50000039],\n       [0.50000009],\n       [0.50000046],\n       [0.50000063],\n       [0.5000001 ],\n       [0.5000007 ],\n       [0.50000185],\n       [0.50000004],\n       [0.50000008],\n       [0.50000016],\n       [0.50000001],\n       [0.50000189],\n       [0.50000063],\n       [0.50000155],\n       [0.50000001],\n       [0.5       ],\n       [0.50000024],\n       [0.50000003],\n       [0.5       ],\n       [0.50000118],\n       [0.50000013],\n       [0.50000004],\n       [0.5       ],\n       [0.50000011],\n       [0.50000004],\n       [0.50000001],\n       [0.50000007],\n       [0.50000227],\n       [0.50000035],\n       [0.50000004],\n       [0.50000077],\n       [0.50000017],\n       [0.50000236],\n       [0.5       ],\n       [0.5000006 ],\n       [0.50000001],\n       [0.50000038],\n       [0.50000014],\n       [0.50000008],\n       [0.50000067],\n       [0.50000079],\n       [0.50000001],\n       [0.50000003],\n       [0.50000014],\n       [0.50000065],\n       [0.50000012],\n       [0.50000161],\n       [0.50000082],\n       [0.50000007],\n       [0.50000092],\n       [0.50000015],\n       [0.5       ],\n       [0.50000047],\n       [0.50000129],\n       [0.50000004],\n       [0.50000003],\n       [0.50000022],\n       [0.50000008],\n       [0.5       ],\n       [0.50000162],\n       [0.50000048],\n       [0.50000064],\n       [0.50000004],\n       [0.5       ],\n       [0.50000117],\n       [0.5       ],\n       [0.50000019],\n       [0.50000022],\n       [0.5000004 ],\n       [0.5000001 ],\n       [0.50000003],\n       [0.50000013],\n       [0.50000001],\n       [0.50000005],\n       [0.50000012],\n       [0.50000048],\n       [0.50000018],\n       [0.50000007],\n       [0.50000014],\n       [0.5000001 ],\n       [0.5000001 ],\n       [0.50000068],\n       [0.5       ],\n       [0.50000211],\n       [0.50000008],\n       [0.50000059],\n       [0.50000082],\n       [0.50000003],\n       [0.50000048],\n       [0.50000108],\n       [0.50000007],\n       [0.50000004],\n       [0.50000235],\n       [0.50000004],\n       [0.50000038],\n       [0.50000007],\n       [0.50000007],\n       [0.5000001 ],\n       [0.50000213],\n       [0.50000004],\n       [0.5       ],\n       [0.50000055],\n       [0.50000014],\n       [0.5000003 ],\n       [0.50000007],\n       [0.50000015],\n       [0.50000174],\n       [0.5000001 ],\n       [0.50000004],\n       [0.500001  ],\n       [0.50000005],\n       [0.5       ],\n       [0.50000217],\n       [0.50000005],\n       [0.50000045],\n       [0.50000042],\n       [0.50000145],\n       [0.5       ],\n       [0.50000049],\n       [0.5       ],\n       [0.50000035],\n       [0.50000015],\n       [0.50000148],\n       [0.50000065],\n       [0.50000062],\n       [0.5       ],\n       [0.50000014],\n       [0.5000009 ],\n       [0.50000007],\n       [0.50000034],\n       [0.50000061],\n       [0.50000016],\n       [0.5       ],\n       [0.5000004 ],\n       [0.5       ],\n       [0.50000004],\n       [0.50000001],\n       [0.50000048],\n       [0.50000003],\n       [0.50000049],\n       [0.50000085],\n       [0.50000019],\n       [0.50000221],\n       [0.50000007],\n       [0.5000001 ],\n       [0.50000033],\n       [0.5000002 ],\n       [0.50000022],\n       [0.5000006 ],\n       [0.50000015],\n       [0.50000008],\n       [0.50000007],\n       [0.50000001],\n       [0.50000012],\n       [0.5       ],\n       [0.50000001],\n       [0.50000003],\n       [0.50000003],\n       [0.50000048],\n       [0.50000012],\n       [0.50000035],\n       [0.50000009],\n       [0.50000004],\n       [0.5       ],\n       [0.50000022],\n       [0.50000021],\n       [0.50000008],\n       [0.50000214],\n       [0.5       ],\n       [0.50000005],\n       [0.50000034],\n       [0.50000013],\n       [0.50000013],\n       [0.50000008],\n       [0.5000001 ],\n       [0.50000081],\n       [0.50000031],\n       [0.50000112],\n       [0.50000061],\n       [0.50000014],\n       [0.50000074],\n       [0.5       ],\n       [0.5       ],\n       [0.50000131],\n       [0.50000082],\n       [0.50000003],\n       [0.50000027],\n       [0.50000103],\n       [0.50000004],\n       [0.50000031],\n       [0.50000018],\n       [0.50000007],\n       [0.5000018 ],\n       [0.50000121],\n       [0.50000009],\n       [0.5       ],\n       [0.50000006],\n       [0.50000002],\n       [0.5       ],\n       [0.50000007],\n       [0.5       ],\n       [0.5       ],\n       [0.50000008],\n       [0.5       ],\n       [0.50000207],\n       [0.5       ],\n       [0.50000006],\n       [0.50000047],\n       [0.50000191],\n       [0.50000013],\n       [0.50000001],\n       [0.50000155],\n       [0.5000001 ],\n       [0.50000005],\n       [0.50000001],\n       [0.5000007 ],\n       [0.5000001 ],\n       [0.5000001 ],\n       [0.50000019],\n       [0.50000046],\n       [0.50000054],\n       [0.50000025],\n       [0.5000002 ],\n       [0.50000005],\n       [0.50000058],\n       [0.50000089],\n       [0.50000008],\n       [0.50000003],\n       [0.50000001],\n       [0.50000018],\n       [0.50000003],\n       [0.50000004],\n       [0.50000049],\n       [0.50000006],\n       [0.50000052],\n       [0.50000053],\n       [0.50000007],\n       [0.50000194],\n       [0.50000036],\n       [0.50000022],\n       [0.50000014],\n       [0.5000001 ],\n       [0.50000022],\n       [0.50000057],\n       [0.50000003],\n       [0.50000173],\n       [0.50000187],\n       [0.50000014],\n       [0.50000005],\n       [0.5       ],\n       [0.50000108],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000001],\n       [0.50000014],\n       [0.50000277],\n       [0.50000087],\n       [0.50000088],\n       [0.50000008],\n       [0.50000012],\n       [0.50000055],\n       [0.50000014],\n       [0.50000004],\n       [0.5       ],\n       [0.50000002],\n       [0.50000273],\n       [0.5       ],\n       [0.50000067],\n       [0.50000046],\n       [0.5       ],\n       [0.50000244],\n       [0.50000002],\n       [0.5000001 ],\n       [0.50000003],\n       [0.50000004],\n       [0.50000014],\n       [0.50000112],\n       [0.50000008],\n       [0.50000065],\n       [0.50000004],\n       [0.50000001],\n       [0.50000131],\n       [0.50000004],\n       [0.50000102],\n       [0.50000088],\n       [0.50000084],\n       [0.5       ],\n       [0.5       ],\n       [0.50000034],\n       [0.50000064],\n       [0.5       ],\n       [0.50000038],\n       [0.50000196],\n       [0.5       ],\n       [0.50000393],\n       [0.5000003 ],\n       [0.5000001 ],\n       [0.50000035],\n       [0.50000024],\n       [0.5000003 ],\n       [0.50000003],\n       [0.5000001 ],\n       [0.50000037],\n       [0.50000082],\n       [0.50000009],\n       [0.50000012],\n       [0.50000436],\n       [0.50000063],\n       [0.50000221],\n       [0.50000016],\n       [0.5000001 ],\n       [0.50000018],\n       [0.50000004],\n       [0.50000078],\n       [0.5       ],\n       [0.50000006],\n       [0.5       ],\n       [0.50000189],\n       [0.50000003],\n       [0.50000001],\n       [0.50000008],\n       [0.50000185],\n       [0.50000008]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_model.predict(dataset=bb_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 12.3: Build a NN model for the cpu.csv dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "cpu_path = r\"C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\datasets\\cpu.csv\"\n",
    "cpu_dataset = read_csv(cpu_path, sep=\",\", features=True, label=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cpu_dataset.x = StandardScaler().fit_transform(cpu_dataset.x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cpu_train, cpu_test = train_test_split(cpu_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cpu_layer1 = Dense(input_size=6, output_size=6)\n",
    "cpu_layer2 = Dense(input_size=6, output_size=4)\n",
    "cpu_layer3 = Dense(input_size=4, output_size=1)\n",
    "\n",
    "cpu_layer1_activation = ReLUActivation()\n",
    "bb_layer2_activation = ReLUActivation()\n",
    "bb_layer3_activation = LinearActivation()\n",
    "\n",
    "cpu_model = NN(\n",
    "    layers=[cpu_layer1, cpu_layer1_activation, cpu_layer2, bb_layer2_activation, cpu_layer3, bb_layer3_activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x16520f0f0d0>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_model.fit(dataset=cpu_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.13111227e-06],\n       [-6.76017322e-07],\n       [-1.39644792e-06],\n       [-2.78539115e-06],\n       [-6.76017322e-07],\n       [-1.30371038e-06],\n       [-2.32644219e-06],\n       [-1.29196940e-06],\n       [-3.46139795e-06],\n       [-1.82919731e-06],\n       [-1.00789345e-06],\n       [-1.37062083e-06],\n       [ 2.11578341e-08],\n       [-1.17380839e-06],\n       [-1.87860492e-06],\n       [-7.22569042e-07],\n       [-1.33810168e-06],\n       [-1.62431495e-06],\n       [-2.45210511e-07],\n       [-1.73859078e-06],\n       [-4.08094887e-06],\n       [-2.15453020e-06],\n       [-2.13924173e-06],\n       [-1.85687441e-06],\n       [-1.46531595e-06],\n       [-7.70320570e-07],\n       [-9.05968106e-07],\n       [-9.87472894e-07],\n       [-1.72513241e-06],\n       [-1.25329029e-06],\n       [-2.88172744e-07],\n       [-1.52969388e-06],\n       [-2.91783575e-06],\n       [-6.76017322e-07],\n       [-1.76327573e-06],\n       [-1.57936143e-06],\n       [-4.71472858e-07],\n       [-1.95605463e-06],\n       [-1.07320710e-06],\n       [-8.19616136e-07],\n       [-1.74776503e-06],\n       [-1.74776503e-06],\n       [-4.44351930e-07],\n       [-9.23080633e-07],\n       [-2.73794199e-06],\n       [-2.91783575e-06],\n       [-9.53108958e-07],\n       [-3.05037657e-07],\n       [-1.38825814e-06],\n       [-1.02699567e-05],\n       [-7.99616052e-07],\n       [-1.46531595e-06],\n       [-1.02296391e-05],\n       [-2.35260881e-06],\n       [-7.31035602e-06],\n       [-4.62151293e-06],\n       [ 0.00000000e+00],\n       [ 2.04340276e-09],\n       [-4.92068739e-07],\n       [-7.52835691e-07],\n       [-1.18025233e-06],\n       [-1.35310951e-06],\n       [-1.49511978e-06],\n       [-9.91786155e-07],\n       [-6.09210138e-08],\n       [-9.19704577e-07],\n       [-3.92793055e-06],\n       [-7.62653862e-07],\n       [-1.87963602e-06],\n       [-1.20373674e-06],\n       [-3.69177971e-06],\n       [-8.33114910e-07],\n       [-5.02055250e-06],\n       [-6.94321152e-07],\n       [-1.50592150e-06],\n       [-7.93799731e-07],\n       [-1.46893376e-06],\n       [-1.44169278e-06],\n       [-1.32355290e-06],\n       [-1.34788981e-06],\n       [-1.16186437e-06],\n       [-1.68822150e-06],\n       [-4.96741863e-07],\n       [-6.30155879e-07],\n       [-3.30582213e-06],\n       [-6.76017322e-07],\n       [ 0.00000000e+00],\n       [-2.91783575e-06],\n       [-1.11610535e-06],\n       [-1.77522600e-06],\n       [-4.71472858e-07],\n       [-1.87880447e-06],\n       [-6.87938971e-07],\n       [-4.94903860e-07],\n       [-1.66654012e-06],\n       [-1.13526626e-06],\n       [-5.99587651e-07],\n       [-1.61528874e-06],\n       [-1.19746771e-06],\n       [-2.52773207e-07],\n       [-3.30639104e-06],\n       [-1.63751995e-06],\n       [-1.31562256e-06],\n       [-1.23073262e-06],\n       [-9.17453872e-07],\n       [-2.78539115e-06],\n       [-1.78818538e-06],\n       [-1.09612183e-06],\n       [-1.18779140e-06],\n       [-3.64603755e-06],\n       [-4.49744041e-07],\n       [-1.25178942e-06],\n       [-7.39072180e-07],\n       [ 2.12662583e-09],\n       [-1.58844179e-06],\n       [-1.96973841e-06],\n       [-4.27556175e-06],\n       [-6.69652885e-07],\n       [-3.11421403e-07],\n       [-5.94400868e-07],\n       [-6.15372306e-07],\n       [-1.76327573e-06],\n       [-8.72817444e-07],\n       [-4.40518966e-07],\n       [-1.97448084e-06],\n       [-5.48047841e-06],\n       [-1.65108755e-06],\n       [-2.45624573e-05],\n       [-1.34740230e-06],\n       [-1.10089612e-05],\n       [-1.15018749e-06],\n       [-6.27866329e-07],\n       [-6.76017322e-07],\n       [-6.52530032e-07],\n       [-7.14340117e-07],\n       [-4.88986279e-07],\n       [-9.52232214e-07],\n       [-1.45974904e-06],\n       [-8.09986903e-07],\n       [-1.21014608e-05],\n       [-6.10737417e-07],\n       [-1.11202652e-05],\n       [-1.29978464e-06],\n       [-7.02674814e-06],\n       [-1.53262081e-06],\n       [-8.89031428e-07],\n       [-6.10604106e-07]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_model.predict(dataset=cpu_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
