{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 12: Neural Networks and Backpropagation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from si.io.data_file import read_data_file\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from si.io.csv import read_csv\n",
    "from si.metrics.cross_entropy import cross_entropy\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.neural_networks.layers import Dense, ReLUActivation, LinearActivation, SigmoidActivation, SoftMaxActivation\n",
    "from si.neural_networks.nn import NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 12.1: Implement the backward propagation method for the ReLUActivation layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def backward(self, error: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the backwards pass of the rectified linear relationship.\n",
    "    :return: Returns the error of the previous layer.\n",
    "    \"\"\"\n",
    "\n",
    "    relu_derivative = np.where(self.x > 0, 1, 0)\n",
    "\n",
    "    error_to_propagate = error * relu_derivative\n",
    "\n",
    "    return error_to_propagate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 12.2: Build a NN model for the breast-bin.csv dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "breast_bin_dataset = r\"C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\datasets\\breast-bin.data\"\n",
    "bb_dataset = read_data_file(breast_bin_dataset, sep=\",\", label=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "bb_dataset.x = StandardScaler().fit_transform(bb_dataset.x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "bb_train, bb_test = train_test_split(bb_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(490, 9)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_train.shape()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "bb_layer1 = Dense(input_size=9, output_size=9)\n",
    "bb_layer2 = Dense(input_size=9, output_size=5)\n",
    "bb_layer3 = Dense(input_size=5, output_size=1)\n",
    "\n",
    "bb_layer1_activation = ReLUActivation()\n",
    "bb_layer2_activation = ReLUActivation()\n",
    "bb_layer3_activation = SigmoidActivation()\n",
    "\n",
    "bb_model = NN(\n",
    "    layers=[bb_layer1, bb_layer1_activation, bb_layer2, bb_layer2_activation, bb_layer3, bb_layer3_activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x25b3136f880>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_model.fit(dataset=bb_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.5000011 ],\n       [0.50000037],\n       [0.5000004 ],\n       [0.50000094],\n       [0.50000026],\n       [0.50000072],\n       [0.50000066],\n       [0.50000094],\n       [0.50000092],\n       [0.50000146],\n       [0.50000182],\n       [0.5000012 ],\n       [0.50000094],\n       [0.50000045],\n       [0.50000056],\n       [0.50000184],\n       [0.50000034],\n       [0.50000163],\n       [0.50000105],\n       [0.50000119],\n       [0.50000042],\n       [0.50000163],\n       [0.50000153],\n       [0.50000008],\n       [0.50000166],\n       [0.50000024],\n       [0.50000094],\n       [0.50000065],\n       [0.50000098],\n       [0.50000141],\n       [0.5       ],\n       [0.50000074],\n       [0.50000124],\n       [0.50000019],\n       [0.50000128],\n       [0.50000152],\n       [0.50000094],\n       [0.50000105],\n       [0.50000084],\n       [0.50000091],\n       [0.50000044],\n       [0.50000026],\n       [0.50000027],\n       [0.50000182],\n       [0.50000034],\n       [0.50000105],\n       [0.5000003 ],\n       [0.50000005],\n       [0.50000081],\n       [0.50000019],\n       [0.50000047],\n       [0.50000141],\n       [0.50000127],\n       [0.50000076],\n       [0.50000141],\n       [0.50000105],\n       [0.5000017 ],\n       [0.50000159],\n       [0.50000108],\n       [0.50000109],\n       [0.50000051],\n       [0.50000163],\n       [0.50000163],\n       [0.50000156],\n       [0.50000146],\n       [0.50000018],\n       [0.50000112],\n       [0.50000016],\n       [0.50000163],\n       [0.50000084],\n       [0.5000011 ],\n       [0.50000174],\n       [0.50000055],\n       [0.50000023],\n       [0.50000049],\n       [0.50000061],\n       [0.50000176],\n       [0.50000182],\n       [0.50000144],\n       [0.50000013],\n       [0.50000105],\n       [0.50000011],\n       [0.50000084],\n       [0.50000075],\n       [0.50000047],\n       [0.50000127],\n       [0.50000105],\n       [0.50000099],\n       [0.50000049],\n       [0.50000076],\n       [0.50000119],\n       [0.50000065],\n       [0.50000151],\n       [0.50000117],\n       [0.50000033],\n       [0.50000141],\n       [0.50000076],\n       [0.50000105],\n       [0.50000105],\n       [0.50000117],\n       [0.50000061],\n       [0.50000127],\n       [0.50000056],\n       [0.50000141],\n       [0.50000105],\n       [0.50000099],\n       [0.50000069],\n       [0.50000127],\n       [0.50000038],\n       [0.50000184],\n       [0.50000141],\n       [0.50000042],\n       [0.50000023],\n       [0.50000132],\n       [0.50000084],\n       [0.50000127],\n       [0.50000116],\n       [0.50000055],\n       [0.50000151],\n       [0.50000099],\n       [0.50000045],\n       [0.50000144],\n       [0.50000141],\n       [0.50000103],\n       [0.50000076],\n       [0.50000094],\n       [0.50000032],\n       [0.50000182],\n       [0.50000141],\n       [0.50000009],\n       [0.50000076],\n       [0.50000163],\n       [0.50000002],\n       [0.50000176],\n       [0.50000016],\n       [0.50000114],\n       [0.50000049],\n       [0.50000105],\n       [0.50000186],\n       [0.50000166],\n       [0.50000084],\n       [0.50000163],\n       [0.50000185],\n       [0.50000097],\n       [0.50000094],\n       [0.50000127],\n       [0.50000136],\n       [0.50000021],\n       [0.50000028],\n       [0.5000003 ],\n       [0.50000295],\n       [0.50000036],\n       [0.50000065],\n       [0.50000076],\n       [0.50000145],\n       [0.50000079],\n       [0.50000151],\n       [0.5000006 ],\n       [0.5       ],\n       [0.5000009 ],\n       [0.50000123],\n       [0.50000105],\n       [0.50000087],\n       [0.50000144],\n       [0.50000086],\n       [0.50000135],\n       [0.50000018],\n       [0.50000138],\n       [0.5000001 ],\n       [0.50000068],\n       [0.50000163],\n       [0.50000002],\n       [0.50000012],\n       [0.50000127],\n       [0.50000141],\n       [0.50000021],\n       [0.50000016],\n       [0.50000093],\n       [0.50000015],\n       [0.5000009 ],\n       [0.50000184],\n       [0.50000094],\n       [0.50000049],\n       [0.5000012 ],\n       [0.50000051],\n       [0.50000012],\n       [0.50000131],\n       [0.50000127],\n       [0.50000094],\n       [0.50000042],\n       [0.50000123],\n       [0.50000143],\n       [0.50000152],\n       [0.50000199],\n       [0.50000038],\n       [0.50000123],\n       [0.50000036],\n       [0.50000026],\n       [0.50000041],\n       [0.50000094],\n       [0.50000184],\n       [0.50000105],\n       [0.5000013 ],\n       [0.50000182],\n       [0.50000141],\n       [0.50000038],\n       [0.50000031],\n       [0.50000105],\n       [0.50000092],\n       [0.50000182],\n       [0.50000112],\n       [0.50000185],\n       [0.50000069],\n       [0.50000018],\n       [0.50000086],\n       [0.50000076],\n       [0.50000114],\n       [0.50000094],\n       [0.5000006 ],\n       [0.50000074],\n       [0.50000127],\n       [0.50000175],\n       [0.50000032],\n       [0.50000141],\n       [0.5000011 ],\n       [0.50000008],\n       [0.50000031],\n       [0.50000087],\n       [0.50000123],\n       [0.50000109],\n       [0.50000069],\n       [0.50000043],\n       [0.50000094],\n       [0.50000045],\n       [0.50000043],\n       [0.50000049],\n       [0.5000012 ],\n       [0.50000035],\n       [0.50000105],\n       [0.50000055],\n       [0.50000122],\n       [0.50000068],\n       [0.50000172],\n       [0.50000151],\n       [0.50000105],\n       [0.50000154],\n       [0.5000006 ],\n       [0.50000026],\n       [0.50000093],\n       [0.50000004],\n       [0.50000141],\n       [0.50000182],\n       [0.5       ],\n       [0.5000012 ],\n       [0.50000157],\n       [0.50000038],\n       [0.50000081],\n       [0.50000134],\n       [0.50000048],\n       [0.50000046],\n       [0.50000034],\n       [0.50000105],\n       [0.50000141],\n       [0.50000163],\n       [0.50000101],\n       [0.50000127],\n       [0.5000011 ],\n       [0.5000002 ],\n       [0.50000116],\n       [0.50000059],\n       [0.50000081],\n       [0.50000114],\n       [0.50000067],\n       [0.50000133],\n       [0.50000123],\n       [0.50000018],\n       [0.50000055],\n       [0.50000084],\n       [0.50000139],\n       [0.50000109],\n       [0.50000025],\n       [0.50000021],\n       [0.50000034],\n       [0.50000045],\n       [0.50000001],\n       [0.50000094],\n       [0.50000021],\n       [0.5000016 ],\n       [0.50000076],\n       [0.50000121],\n       [0.5000008 ],\n       [0.50000099],\n       [0.50000052],\n       [0.50000037],\n       [0.50000151],\n       [0.50000072],\n       [0.50000003],\n       [0.50000061],\n       [0.50000084],\n       [0.50000113],\n       [0.50000084],\n       [0.50000123],\n       [0.50000105],\n       [0.50000037],\n       [0.5000012 ],\n       [0.5000007 ],\n       [0.50000075],\n       [0.50000037],\n       [0.50000002],\n       [0.50000151],\n       [0.50000063],\n       [0.50000142],\n       [0.50000136],\n       [0.50000139],\n       [0.50000063],\n       [0.50000116],\n       [0.50000141],\n       [0.50000141],\n       [0.50000105],\n       [0.50000082],\n       [0.50000086],\n       [0.50000105],\n       [0.5000012 ],\n       [0.5000012 ],\n       [0.50000166],\n       [0.50000185],\n       [0.50000038],\n       [0.50000123],\n       [0.50000123],\n       [0.50000084],\n       [0.50000067],\n       [0.500001  ],\n       [0.50000001],\n       [0.50000006],\n       [0.50000063],\n       [0.50000115],\n       [0.50000114],\n       [0.50000159],\n       [0.50000135],\n       [0.50000087],\n       [0.50000133],\n       [0.50000143],\n       [0.50000076],\n       [0.50000069],\n       [0.50000063],\n       [0.50000182],\n       [0.50000001],\n       [0.50000076],\n       [0.50000086],\n       [0.50000043],\n       [0.50000105],\n       [0.5000012 ],\n       [0.50000057],\n       [0.50000082],\n       [0.50000123],\n       [0.50000089],\n       [0.49999997],\n       [0.50000141],\n       [0.50000207],\n       [0.50000003],\n       [0.50000123],\n       [0.50000094],\n       [0.5000012 ],\n       [0.50000071],\n       [0.50000084],\n       [0.50000066],\n       [0.5000008 ],\n       [0.50000084],\n       [0.50000065],\n       [0.50000084],\n       [0.50000109],\n       [0.50000094],\n       [0.50000142],\n       [0.50000043],\n       [0.50000039],\n       [0.50000101],\n       [0.50000105],\n       [0.50000039],\n       [0.50000163],\n       [0.50000055],\n       [0.50000105],\n       [0.50000151],\n       [0.50000174],\n       [0.50000144],\n       [0.50000048],\n       [0.50000022],\n       [0.50000069],\n       [0.50000163],\n       [0.50000192],\n       [0.5000013 ],\n       [0.50000052],\n       [0.50000077],\n       [0.50000141],\n       [0.5000012 ],\n       [0.50000105],\n       [0.50000128],\n       [0.50000029],\n       [0.50000127],\n       [0.5000007 ],\n       [0.50000056],\n       [0.50000025],\n       [0.5       ],\n       [0.50000141],\n       [0.5000004 ],\n       [0.5000007 ],\n       [0.50000155],\n       [0.50000049],\n       [0.50000133],\n       [0.50000107],\n       [0.50000075],\n       [0.50000084],\n       [0.50000009],\n       [0.50000062],\n       [0.50000162],\n       [0.50000055],\n       [0.50000084],\n       [0.50000077],\n       [0.50000099],\n       [0.50000152],\n       [0.50000084],\n       [0.50000052],\n       [0.50000047],\n       [0.50000047],\n       [0.50000024],\n       [0.50000006],\n       [0.50000069],\n       [0.50000139],\n       [0.50000147],\n       [0.50000116],\n       [0.50000059],\n       [0.50000082],\n       [0.50000108],\n       [0.50000087],\n       [0.50000084],\n       [0.50000058],\n       [0.50000124],\n       [0.50000085],\n       [0.50000071],\n       [0.50000118],\n       [0.50000174],\n       [0.50000074],\n       [0.50000127],\n       [0.50000105],\n       [0.50000127],\n       [0.50000065],\n       [0.50000096],\n       [0.50000017],\n       [0.50000105],\n       [0.5000005 ],\n       [0.50000127],\n       [0.50000117],\n       [0.50000063],\n       [0.50000073],\n       [0.50000089],\n       [0.50000148],\n       [0.50000067],\n       [0.50000091],\n       [0.5000011 ],\n       [0.50000006],\n       [0.5       ],\n       [0.50000152],\n       [0.5000006 ],\n       [0.50000009],\n       [0.50000174],\n       [0.50000075],\n       [0.50000303],\n       [0.50000064],\n       [0.50000042],\n       [0.50000163],\n       [0.50000069],\n       [0.50000052],\n       [0.50000143],\n       [0.50000134],\n       [0.50000051],\n       [0.5000009 ],\n       [0.50000058],\n       [0.50000114],\n       [0.50000163],\n       [0.50000153],\n       [0.50000127],\n       [0.5       ],\n       [0.50000094],\n       [0.50000142],\n       [0.50000084],\n       [0.50000041],\n       [0.5000012 ],\n       [0.50000105],\n       [0.50000065],\n       [0.50000077],\n       [0.50000065]])"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_model.predict(dataset=bb_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 12.3: Build a NN model for the cpu.csv dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "cpu_path = r\"C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\datasets\\cpu.csv\"\n",
    "cpu_dataset = read_csv(cpu_path, sep=\",\", features=True, label=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "cpu_dataset.x = StandardScaler().fit_transform(cpu_dataset.x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "cpu_train, cpu_test = train_test_split(cpu_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "cpu_layer1 = Dense(input_size=6, output_size=6)\n",
    "cpu_layer2 = Dense(input_size=6, output_size=4)\n",
    "cpu_layer3 = Dense(input_size=4, output_size=1)\n",
    "\n",
    "cpu_layer1_activation = ReLUActivation()\n",
    "bb_layer2_activation = ReLUActivation()\n",
    "bb_layer3_activation = SigmoidActivation()\n",
    "\n",
    "cpu_model = NN(\n",
    "    layers=[cpu_layer1, cpu_layer1_activation, cpu_layer2, bb_layer2_activation, cpu_layer3, bb_layer3_activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x25b3136e2f0>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_model.fit(dataset=cpu_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.499998  ],\n       [0.49999576],\n       [0.49999792],\n       [0.50000185],\n       [0.49999576],\n       [0.49999894],\n       [0.50000082],\n       [0.49999893],\n       [0.49999858],\n       [0.49999904],\n       [0.49999993],\n       [0.49999969],\n       [0.50000101],\n       [0.4999958 ],\n       [0.4999984 ],\n       [0.49999962],\n       [0.49999788],\n       [0.49999914],\n       [0.49999548],\n       [0.49999833],\n       [0.49999936],\n       [0.50000063],\n       [0.49999738],\n       [0.4999978 ],\n       [0.49999917],\n       [0.50000064],\n       [0.49999871],\n       [0.49999543],\n       [0.49999812],\n       [0.49999902],\n       [0.49999975],\n       [0.49999937],\n       [0.49999909],\n       [0.49999576],\n       [0.49999858],\n       [0.50000008],\n       [0.50000006],\n       [0.4999973 ],\n       [0.49999968],\n       [0.49999837],\n       [0.49999857],\n       [0.49999857],\n       [0.50000011],\n       [0.49999957],\n       [0.50000033],\n       [0.49999909],\n       [0.50000031],\n       [0.49999215],\n       [0.4999996 ],\n       [0.49999658],\n       [0.49999623],\n       [0.49999917],\n       [0.49999801],\n       [0.50000089],\n       [0.49999617],\n       [0.50000099],\n       [0.49999943],\n       [0.50000065],\n       [0.50000009],\n       [0.49999916],\n       [0.49999885],\n       [0.49999809],\n       [0.49999946],\n       [0.49999915],\n       [0.49999989],\n       [0.49999957],\n       [0.49999769],\n       [0.4999984 ],\n       [0.49999836],\n       [0.4999994 ],\n       [0.50000109],\n       [0.49999788],\n       [0.5000004 ],\n       [0.49999886],\n       [0.49999805],\n       [0.50000049],\n       [0.49999938],\n       [0.49999919],\n       [0.49999939],\n       [0.49999919],\n       [0.49999881],\n       [0.49999741],\n       [0.50000034],\n       [0.49999401],\n       [0.5000003 ],\n       [0.49999576],\n       [0.49999933],\n       [0.49999909],\n       [0.50000034],\n       [0.49999684],\n       [0.50000006],\n       [0.49999742],\n       [0.50000004],\n       [0.49999949],\n       [0.49999865],\n       [0.49999983],\n       [0.50000029],\n       [0.49999859],\n       [0.4999994 ],\n       [0.4999997 ],\n       [0.5000003 ],\n       [0.49999791],\n       [0.49999888],\n       [0.49999968],\n       [0.49999957],\n       [0.50000185],\n       [0.49999843],\n       [0.49999979],\n       [0.49999987],\n       [0.50000072],\n       [0.50000086],\n       [0.49999936],\n       [0.4999993 ],\n       [0.5000006 ],\n       [0.49999792],\n       [0.49999674],\n       [0.49999742],\n       [0.49999893],\n       [0.49999916],\n       [0.49999926],\n       [0.50000071],\n       [0.49999858],\n       [0.4999986 ],\n       [0.49999868],\n       [0.49999775],\n       [0.50000058],\n       [0.4999976 ],\n       [0.50000052],\n       [0.49999884],\n       [0.49999658],\n       [0.50000027],\n       [0.49999979],\n       [0.49999576],\n       [0.49999991],\n       [0.49999943],\n       [0.49999939],\n       [0.49999876],\n       [0.49999973],\n       [0.49999902],\n       [0.49999996],\n       [0.49999407],\n       [0.50000001],\n       [0.49999939],\n       [0.50000166],\n       [0.49999885],\n       [0.49999559],\n       [0.49999974]])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_model.predict(dataset=cpu_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
