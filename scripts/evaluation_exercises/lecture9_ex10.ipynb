{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NN Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from si.neural_networks.layers import Dense, SigmoidActivation, SoftMaxActivation, ReLUActivation, LinearActivation\n",
    "from si.neural_networks.nn import NN\n",
    "from si.data.dataset import Dataset\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   x1  x2\n1   0   0\n0   0   1\n0   1   0\n1   1   1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "\n",
    "y = np.array([1,\n",
    "              0,\n",
    "              0,\n",
    "              1])\n",
    "\n",
    "dataset = Dataset(x=x, y=y, features_names=['x1', 'x2'], label_name='x1 XNOR x2')\n",
    "dataset.print_dataframe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# weights and bias for the 1st layer\n",
    "\n",
    "# first row is the first node of the second layer\n",
    "# rows are the input nodes\n",
    "l1_weight_matrix = np.array([[20, -20],\n",
    "                             [20, -20]])\n",
    "\n",
    "l1_bias = np.array([[-30, 10]])\n",
    "\n",
    "layer1 = Dense(input_size=2, output_size=2)\n",
    "layer1.weights = l1_weight_matrix\n",
    "layer1.bias = l1_bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# weights and bias for the 2nd layer\n",
    "\n",
    "l2_weight_matrix = np.array([[20],\n",
    "                             [20]])\n",
    "\n",
    "l2_bias = np.array([[-10]])\n",
    "\n",
    "layer2 = Dense(input_size=2, output_size=1)\n",
    "layer2.weights = l2_weight_matrix\n",
    "layer2.bias = l2_bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "layer1_sigmoid = SigmoidActivation()\n",
    "layer2_sigmoid = SigmoidActivation()\n",
    "\n",
    "# between layers, we have the layer activation\n",
    "nn_model = NN(\n",
    "    layers=[layer1, layer1_sigmoid, layer2, layer2_sigmoid]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x261b2585cf0>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(dataset=dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[9.99954561e-01],\n       [4.54803785e-05],\n       [4.54803785e-05],\n       [9.99954561e-01]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.predict(dataset=dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ex.10 Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex.10.3\n",
    "Binary classification problem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Create an adequate training dataset\n",
    "x_3 = np.random.randn(100, 32)  # 100 samples with 32 features of random floats\n",
    "y_3 = np.random.randint(0, 2, size=(100, 1))  # labels for the 100 samples of random binary integers\n",
    "\n",
    "dataset_3 = Dataset(x_3, y_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "layer3_1 = Dense(input_size=32, output_size=32)\n",
    "layer3_2 = Dense(input_size=32, output_size=16)\n",
    "layer3_3 = Dense(input_size=16, output_size=1)  #if score is <0.5 the output is 0, and if score is >0.5 the output is 1\n",
    "\n",
    "layer3_1activation = SigmoidActivation()\n",
    "layer3_2activation = SigmoidActivation()\n",
    "layer3_3activation= SigmoidActivation()\n",
    "\n",
    "# between layers, we have the layer activation\n",
    "nn_model3 = NN(\n",
    "    layers=[layer3_1, layer3_1activation, layer3_2, layer3_2activation, layer3_3, layer3_3activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x261b28731c0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model3.fit(dataset=dataset_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.49531054],\n       [0.49531202],\n       [0.49531226],\n       [0.49531231],\n       [0.49530959],\n       [0.49531031],\n       [0.49530841],\n       [0.49531074],\n       [0.49531313],\n       [0.49531266],\n       [0.49531117],\n       [0.49531007],\n       [0.49530977],\n       [0.49531537],\n       [0.49531297],\n       [0.49531032],\n       [0.49530931],\n       [0.49531098],\n       [0.49530775],\n       [0.49531011],\n       [0.49531225],\n       [0.49531541],\n       [0.49531345],\n       [0.495309  ],\n       [0.49531431],\n       [0.49531149],\n       [0.49531263],\n       [0.49531111],\n       [0.49531024],\n       [0.49530993],\n       [0.49531263],\n       [0.49531377],\n       [0.49531327],\n       [0.49531067],\n       [0.49531117],\n       [0.49530926],\n       [0.49531016],\n       [0.49531077],\n       [0.49531369],\n       [0.49531144],\n       [0.49531121],\n       [0.49530972],\n       [0.4953091 ],\n       [0.49531303],\n       [0.49531048],\n       [0.4953079 ],\n       [0.49531402],\n       [0.49531122],\n       [0.49531163],\n       [0.49531138],\n       [0.49530746],\n       [0.49531042],\n       [0.49531164],\n       [0.49531022],\n       [0.49531181],\n       [0.49531458],\n       [0.49531121],\n       [0.49531128],\n       [0.49531371],\n       [0.49531086],\n       [0.49531101],\n       [0.49531386],\n       [0.49531442],\n       [0.49530953],\n       [0.49531239],\n       [0.49531068],\n       [0.49531169],\n       [0.49530849],\n       [0.49530928],\n       [0.49531251],\n       [0.49531297],\n       [0.49531683],\n       [0.49530826],\n       [0.49531231],\n       [0.49530696],\n       [0.49531153],\n       [0.49531153],\n       [0.49530971],\n       [0.49531113],\n       [0.4953124 ],\n       [0.49531422],\n       [0.49531322],\n       [0.49530992],\n       [0.49531447],\n       [0.49530957],\n       [0.49531278],\n       [0.49531641],\n       [0.49531121],\n       [0.49531272],\n       [0.49531442],\n       [0.4953134 ],\n       [0.49530871],\n       [0.4953116 ],\n       [0.49531185],\n       [0.49531003],\n       [0.49530951],\n       [0.49530865],\n       [0.49531152],\n       [0.49531127],\n       [0.49531421]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model3.predict(dataset=dataset_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex.10.4\n",
    "Multiclass classification problem (3 classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Create an adequate training dataset\n",
    "x_4 = np.random.randn(100, 32)  # 100 samples with 32 features of random floats\n",
    "y_4 = np.random.randint(0, 3, size=(100, 1))  # labels for the 100 samples with 3 different classes\n",
    "\n",
    "dataset_4 = Dataset(x_4, y_4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "layer4_1 = Dense(input_size=32, output_size=32)\n",
    "layer4_2 = Dense(input_size=32, output_size=16)\n",
    "layer4_3 = Dense(input_size=16, output_size=3)  # will assign each output to the corresponding class according to the score\n",
    "\n",
    "layer4_1activation = SigmoidActivation()\n",
    "layer4_2activation= SigmoidActivation()\n",
    "layer4_3activation = SoftMaxActivation()  # will assign a probability to each class that summed together will add up to 1\n",
    "\n",
    "# between layers, we have the layer activation\n",
    "nn_model4 = NN(\n",
    "    layers=[layer4_1, layer4_1activation, layer4_2, layer4_2activation, layer4_3, layer4_3activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x261b25c1780>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model4.fit(dataset=dataset_4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.33869774, 0.33102582, 0.33027644],\n       [0.33870107, 0.33102503, 0.33027389],\n       [0.33870404, 0.33102199, 0.33027397],\n       [0.33870075, 0.33102475, 0.33027449],\n       [0.33870338, 0.33102391, 0.33027271],\n       [0.33870375, 0.33102629, 0.33026996],\n       [0.33870223, 0.33102258, 0.33027519],\n       [0.33869857, 0.33102539, 0.33027605],\n       [0.33870193, 0.33102563, 0.33027244],\n       [0.33870059, 0.33102557, 0.33027384],\n       [0.33869906, 0.33102388, 0.33027706],\n       [0.33870234, 0.33102509, 0.33027257],\n       [0.33870123, 0.33102504, 0.33027372],\n       [0.33869999, 0.3310242 , 0.33027581],\n       [0.33869913, 0.33102529, 0.33027558],\n       [0.33869946, 0.3310246 , 0.33027594],\n       [0.33869897, 0.33102422, 0.33027681],\n       [0.33870048, 0.33102497, 0.33027455],\n       [0.33869898, 0.3310249 , 0.33027611],\n       [0.33869956, 0.33102591, 0.33027453],\n       [0.33870149, 0.33102652, 0.33027198],\n       [0.33870234, 0.33102335, 0.33027431],\n       [0.33870105, 0.33102553, 0.33027342],\n       [0.33870265, 0.33102518, 0.33027217],\n       [0.33869961, 0.33102582, 0.33027457],\n       [0.33870106, 0.33102414, 0.3302748 ],\n       [0.33869868, 0.33102555, 0.33027577],\n       [0.33869951, 0.33102844, 0.33027205],\n       [0.33870297, 0.33102384, 0.33027319],\n       [0.33869794, 0.33102718, 0.33027488],\n       [0.33870256, 0.33102339, 0.33027405],\n       [0.33870074, 0.3310261 , 0.33027315],\n       [0.33870318, 0.33102413, 0.33027269],\n       [0.33869989, 0.33102223, 0.33027788],\n       [0.33870205, 0.33102291, 0.33027505],\n       [0.33870215, 0.3310247 , 0.33027316],\n       [0.33869964, 0.33102608, 0.33027428],\n       [0.33869883, 0.33102729, 0.33027388],\n       [0.33870399, 0.33102497, 0.33027104],\n       [0.33869987, 0.33102525, 0.33027488],\n       [0.33870158, 0.33102554, 0.33027288],\n       [0.33870057, 0.3310257 , 0.33027372],\n       [0.3387026 , 0.33102247, 0.33027493],\n       [0.33869937, 0.33102322, 0.33027741],\n       [0.33870232, 0.33102443, 0.33027326],\n       [0.338703  , 0.33102253, 0.33027447],\n       [0.33869994, 0.33102305, 0.330277  ],\n       [0.33870462, 0.33102625, 0.33026913],\n       [0.33869925, 0.33102343, 0.33027732],\n       [0.33869894, 0.33102581, 0.33027525],\n       [0.33870307, 0.33102413, 0.3302728 ],\n       [0.33869977, 0.33102406, 0.33027617],\n       [0.33869845, 0.33102386, 0.33027769],\n       [0.33870255, 0.33102495, 0.3302725 ],\n       [0.33869877, 0.33102602, 0.33027522],\n       [0.33870192, 0.33102623, 0.33027185],\n       [0.33870228, 0.33102481, 0.33027291],\n       [0.33870293, 0.33102747, 0.3302696 ],\n       [0.33870016, 0.33102447, 0.33027536],\n       [0.33870115, 0.33102507, 0.33027378],\n       [0.33870261, 0.33102382, 0.33027357],\n       [0.3386979 , 0.33102709, 0.33027501],\n       [0.33870432, 0.33102413, 0.33027155],\n       [0.338703  , 0.33102478, 0.33027222],\n       [0.3387033 , 0.33102658, 0.33027012],\n       [0.33870264, 0.33102521, 0.33027215],\n       [0.33870287, 0.33102523, 0.3302719 ],\n       [0.33870094, 0.33102603, 0.33027303],\n       [0.33870337, 0.33102475, 0.33027188],\n       [0.33869721, 0.33102653, 0.33027626],\n       [0.3386986 , 0.33102366, 0.33027774],\n       [0.33870104, 0.33102395, 0.33027501],\n       [0.33870042, 0.33102646, 0.33027312],\n       [0.33869929, 0.33102451, 0.33027619],\n       [0.33869933, 0.33102387, 0.3302768 ],\n       [0.33870223, 0.33102661, 0.33027115],\n       [0.33870085, 0.33102641, 0.33027275],\n       [0.338698  , 0.33102472, 0.33027729],\n       [0.33870277, 0.33102584, 0.3302714 ],\n       [0.33870017, 0.33102554, 0.33027428],\n       [0.33870281, 0.33102394, 0.33027325],\n       [0.33870398, 0.33102433, 0.33027169],\n       [0.33870397, 0.3310251 , 0.33027093],\n       [0.3387007 , 0.33102344, 0.33027586],\n       [0.33869862, 0.33102476, 0.33027662],\n       [0.33870451, 0.33102336, 0.33027213],\n       [0.33869884, 0.33102827, 0.33027289],\n       [0.33870029, 0.33102382, 0.33027589],\n       [0.33870263, 0.33102569, 0.33027168],\n       [0.33870123, 0.33102553, 0.33027324],\n       [0.33869963, 0.33102625, 0.33027413],\n       [0.33870083, 0.33102561, 0.33027356],\n       [0.33870068, 0.33102596, 0.33027337],\n       [0.33870097, 0.33102612, 0.33027291],\n       [0.33870001, 0.33102849, 0.33027149],\n       [0.33870049, 0.33102546, 0.33027406],\n       [0.33870024, 0.33102683, 0.33027293],\n       [0.33870269, 0.33102409, 0.33027322],\n       [0.33869933, 0.33102595, 0.33027472],\n       [0.33870108, 0.33102384, 0.33027508]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model4.predict(dataset=dataset_4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ex.10.5\n",
    "Regression problem"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Create an adequate training dataset\n",
    "x_5 = np.random.randn(100, 32)  # 100 samples with 32 features of random floats\n",
    "y_5 = np.random.randn(100, 1)  # labels for the 100 samples of random floats\n",
    "\n",
    "dataset_5 = Dataset(x_5, y_5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "layer5_1 = Dense(input_size=32, output_size=32)\n",
    "layer5_2 = Dense(input_size=32, output_size=16)\n",
    "layer5_3 = Dense(input_size=16, output_size=1)  # returns a single continuous target for each sample\n",
    "\n",
    "layer5_1activation = ReLUActivation()\n",
    "layer5_2activation = ReLUActivation()\n",
    "layer5_3activation = LinearActivation()  # returns a real values for our output\n",
    "\n",
    "# between layers, we have the layer activation\n",
    "nn_model5 = NN(\n",
    "    layers=[layer5_1, layer5_1activation, layer5_2, layer5_2activation, layer5_3, layer5_3activation]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<si.neural_networks.nn.NN at 0x261b25c0490>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model5.fit(dataset=dataset_5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-6.60358704e-05],\n       [-1.12359754e-05],\n       [-1.06814322e-05],\n       [-2.76392044e-05],\n       [ 2.13469987e-05],\n       [-3.28900541e-05],\n       [ 1.76485669e-05],\n       [ 9.64168790e-06],\n       [-3.67726719e-05],\n       [-1.77240298e-05],\n       [-1.75230350e-05],\n       [ 1.28876323e-04],\n       [-2.17718571e-05],\n       [-5.96350542e-05],\n       [ 2.65359736e-05],\n       [ 2.46386781e-05],\n       [ 2.19052468e-05],\n       [ 5.06382657e-06],\n       [-7.27715136e-06],\n       [ 1.10217510e-05],\n       [ 1.40806531e-05],\n       [-6.39781703e-05],\n       [ 2.39786576e-07],\n       [ 4.13656276e-05],\n       [-2.29751322e-05],\n       [-3.36637186e-05],\n       [-2.43219275e-05],\n       [-2.14289027e-05],\n       [ 8.35662083e-05],\n       [-4.42453840e-05],\n       [-3.89488564e-05],\n       [ 3.58399024e-06],\n       [ 2.62989095e-05],\n       [-2.17567413e-05],\n       [-2.98511016e-05],\n       [ 6.73300754e-05],\n       [-2.11959912e-05],\n       [ 3.79895509e-07],\n       [ 6.56216299e-05],\n       [-2.22885742e-05],\n       [ 6.49045140e-05],\n       [ 2.06719160e-05],\n       [ 1.01546787e-05],\n       [-4.18122022e-05],\n       [ 8.76672803e-05],\n       [-1.55981692e-05],\n       [-3.04821131e-05],\n       [ 2.43507036e-05],\n       [-2.53126544e-05],\n       [ 7.84457432e-07],\n       [-4.55359907e-06],\n       [-3.34211648e-06],\n       [ 5.01584295e-05],\n       [ 5.70113437e-05],\n       [-3.60718041e-05],\n       [ 5.84343771e-05],\n       [-3.32874559e-05],\n       [-8.47004711e-05],\n       [ 2.63557173e-05],\n       [ 5.48587766e-05],\n       [ 3.30381913e-05],\n       [ 2.14971281e-05],\n       [-3.04946313e-06],\n       [ 6.52394536e-05],\n       [-4.70602192e-06],\n       [-3.49000205e-05],\n       [-4.08445242e-05],\n       [-5.26481755e-05],\n       [-4.72159091e-05],\n       [-1.49473549e-05],\n       [-3.02275158e-05],\n       [ 1.43216350e-05],\n       [-2.60708747e-05],\n       [ 5.21850996e-05],\n       [ 5.70671531e-05],\n       [-2.90438089e-05],\n       [ 7.96022917e-05],\n       [-1.48500218e-05],\n       [ 2.10375330e-05],\n       [-4.66110600e-05],\n       [-8.99131623e-05],\n       [ 2.27733555e-05],\n       [-1.74842629e-06],\n       [-8.12693527e-06],\n       [ 4.60328623e-05],\n       [ 4.62074936e-05],\n       [ 2.10882373e-05],\n       [-4.87463683e-05],\n       [-9.04942839e-06],\n       [ 4.74007573e-05],\n       [ 1.15079254e-05],\n       [-1.41326550e-05],\n       [-6.49120920e-05],\n       [ 4.59533544e-05],\n       [ 1.60455449e-05],\n       [-2.00222419e-05],\n       [-7.26987859e-05],\n       [-4.18285603e-05],\n       [-3.25917865e-05],\n       [ 2.34497711e-05]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model5.predict(dataset=dataset_5)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
