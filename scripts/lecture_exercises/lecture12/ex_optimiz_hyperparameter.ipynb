{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of hyperparameter optimization in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxsyA9Wni-b-"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "## function to setup model (assuming multiclass classification problem)\n",
    "# topo -> topology graph\n",
    "# input and output size are not hyperparameters to be optimized and are intrinsic to the data\n",
    "# can also add functions as a hyperparameter such as scoring functions or activation functions\n",
    "\n",
    "def setup_model(topo, dropout_rate, input_size, output_size,activation_func='softmax'):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(topo[0], activation=\"relu\", input_dim = input_size))\n",
    "    if dropout_rate > 0: model.add(Dropout(dropout_rate))\n",
    "    for i in range(1,len(topo)):        \n",
    "        model.add(Dense(topo[i], activation=\"relu\"))\n",
    "        if dropout_rate > 0: model.add(Dropout(dropout_rate))    \n",
    "    model.add(Dense(output_size))\n",
    "    model.add(Activation(activation_func))\n",
    "    \n",
    "    return model\n",
    "\n",
    "## training the DNN - takes algorithm (string) and learning rate; data (X, y), epochs and batch size\n",
    "def train_dnn(model, alg, lr, x_train, y_train, epochs = 5, batch_size = 64, metric_function: List = ['accuracy', 'mse']):\n",
    "    if alg == \"adam\":\n",
    "        optimizer = optimizers.Adam(lr = lr)\n",
    "    elif alg == \"rmsprop\":\n",
    "        optimizer = optimizers.RMSprop(lr = lr)\n",
    "    elif alg == \"sgd_momentum\":\n",
    "        optimizer = optimizers.SGD(lr = lr, momentum = 0.9)\n",
    "    else: optimizer = optimizers.SGD(lr = lr)\n",
    "        \n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = metric_function)\n",
    "    model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "## optimizing parameters: topology, algorithm, learning rate, dropout\n",
    "## randomized search optimization with maximum iterations\n",
    "## takes as input: dictionary with params to optimizae and possible values; training data(X,y), validation data (X,y), iterations, epochs for training\n",
    "def dnn_optimization(opt_params, x_train, y_train, x_valid, y_valid, iterations = 10, epochs = 5, verbose = True):\n",
    "    from random import choice\n",
    "  \n",
    "    if verbose: \n",
    "        print(\"Topology\\tDropout\\tAlgorithm\\tLRate\\tValLoss\\tValAcc\\n\")\n",
    "    best_acc = None\n",
    "    \n",
    "    input_size = x_train.shape[1]\n",
    "    output_size = y_train.shape[1]\n",
    "    \n",
    "    if \"topology\" in opt_params:\n",
    "        topologies = opt_params[\"topology\"]\n",
    "    else: topologies = [[100]]\n",
    "    if \"algorithm\" in opt_params:\n",
    "        algs = opt_params[\"algorithm\"]\n",
    "    else: algs = [\"adam\"]\n",
    "    if \"lr\" in opt_params:\n",
    "        lrs = opt_params[\"lr\"]\n",
    "    else: lrs = [0.001]\n",
    "    if \"dropout\" in opt_params:\n",
    "        dropouts = opt_params[\"dropout\"]\n",
    "    else: dropouts= [0.0]\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        topo = choice(topologies)\n",
    "        dropout_rate = choice(dropouts)\n",
    "        dnn = setup_model (topo, dropout_rate, input_size, output_size)\n",
    "        alg = choice(algs)\n",
    "        lr = choice(lrs)\n",
    "        dnn = train_dnn(dnn, alg, lr, x_train, y_train, epochs, 128)\n",
    "        val_loss, val_acc = dnn.evaluate(x_valid, y_valid, verbose = 0)\n",
    "        \n",
    "        if verbose: \n",
    "            print(topo, \"\\t\", dropout_rate, \"\\t\", alg, \"\\t\", lr, \"\\t\", val_loss, \"\\t\", val_acc)\n",
    "        \n",
    "        if best_acc is None or val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_config = (topo, dropout_rate, alg, lr)\n",
    "        \n",
    "    return best_config, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with MNIST dataset - DNNs with hyperparameters optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-4j0VvLEjK-X",
    "outputId": "4e08fe90-79c5-426f-fb15-9fd60af192f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "60000 10000\n",
      "(50000, 784) (10000, 784) (10000, 784)\n",
      "50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "print(len(train_labels), len(test_labels))\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "X_test = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "X_tr = train_images[:50000,]\n",
    "X_val = train_images[50000:,]\n",
    "y_tr = train_labels[:50000]\n",
    "y_val = train_labels[50000:,]\n",
    "\n",
    "print(X_tr.shape, X_val.shape, X_test.shape)\n",
    "print(len(y_tr), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "hJnLtsYUmDhA",
    "outputId": "6be431e1-6f49-4b76-fc9b-95016f439d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology\tDropout\tAlgorithm\tLRate\tValLoss\tValAcc\n",
      "\n",
      "[100, 50] \t 0.5 \t adam \t 0.01 \t 0.19035480916500092 \t 0.9517999887466431\n",
      "[250] \t 0 \t adam \t 0.001 \t 0.0788038820028305 \t 0.9767000079154968\n",
      "[100, 50] \t 0.2 \t rmsprop \t 0.01 \t 0.14397594332695007 \t 0.9674000144004822\n",
      "[250] \t 0 \t sgd_momentum \t 0.01 \t 0.15039779245853424 \t 0.9588000178337097\n",
      "[100] \t 0.5 \t sgd_momentum \t 0.01 \t 0.16686806082725525 \t 0.954800009727478\n",
      "[100, 50] \t 0.2 \t adam \t 0.001 \t 0.09524358808994293 \t 0.9718000292778015\n",
      "[100] \t 0.5 \t rmsprop \t 0.001 \t 0.1300782710313797 \t 0.9635999798774719\n",
      "[100, 50] \t 0.2 \t sgd_momentum \t 0.001 \t 0.34068548679351807 \t 0.9067000150680542\n",
      "[100] \t 0.5 \t adam \t 0.01 \t 0.14045625925064087 \t 0.963100016117096\n",
      "[100, 50] \t 0.5 \t sgd_momentum \t 0.001 \t 0.4231471121311188 \t 0.897599995136261\n",
      "[250, 100] \t 0.5 \t sgd_momentum \t 0.01 \t 0.12872694432735443 \t 0.9642999768257141\n",
      "[100] \t 0.5 \t rmsprop \t 0.01 \t 0.20177757740020752 \t 0.9534000158309937\n",
      "[250, 100] \t 0.5 \t rmsprop \t 0.001 \t 0.10931070894002914 \t 0.9728999733924866\n",
      "[100, 50] \t 0 \t adam \t 0.001 \t 0.10444685071706772 \t 0.9689000248908997\n",
      "[250, 100] \t 0.2 \t adam \t 0.001 \t 0.07431840896606445 \t 0.977400004863739\n",
      "[100] \t 0 \t adam \t 0.01 \t 0.13180018961429596 \t 0.9667999744415283\n",
      "[100, 50] \t 0 \t rmsprop \t 0.01 \t 0.1656186729669571 \t 0.9678000211715698\n",
      "[250, 100] \t 0.2 \t sgd_momentum \t 0.01 \t 0.10706847906112671 \t 0.9702000021934509\n",
      "[100, 50] \t 0 \t adam \t 0.001 \t 0.11117064207792282 \t 0.9674000144004822\n",
      "[100, 50] \t 0.5 \t rmsprop \t 0.01 \t 0.2625890374183655 \t 0.9448999762535095\n",
      "Best configuration: ([250, 100], 0.2, 'adam', 0.001)\n",
      "Best validation accuracy: 0.977400004863739\n"
     ]
    }
   ],
   "source": [
    "opt_pars = {\"topology\":[[100], [100,50], [250], [250,100]],\n",
    "            \"algorithm\": [ \"adam\", \"rmsprop\", \"sgd_momentum\"],\n",
    "            \"lr\": [0.01, 0.001],\n",
    "            \"dropout\": [0, 0.2, 0.5]}\n",
    "\n",
    "best_config, best_val_acc = dnn_optimization(opt_pars, X_tr, y_tr, X_val, y_val, 20)  \n",
    "print(\"Best configuration:\", best_config)\n",
    "print(\"Best validation accuracy:\", best_val_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7IL7shHMouMQ",
    "outputId": "0c171279-660a-41e9-b336-d2aae7efbac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set metrics: 0.07228674739599228 0.9787999987602234\n"
     ]
    }
   ],
   "source": [
    "# take best configuration and retrain with whole training set\n",
    "# evaluate error on holdout test set\n",
    "best_model = setup_model(best_config[0], best_config[1], X_tr.shape[1], y_tr.shape[1])\n",
    "best_model = train_dnn(best_model, best_config[2], best_config[3], train_images, train_labels)\n",
    "\n",
    "test_loo, test_acc = best_model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test set metrics:\", test_loo, test_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ex_optimiz_hyperpar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
