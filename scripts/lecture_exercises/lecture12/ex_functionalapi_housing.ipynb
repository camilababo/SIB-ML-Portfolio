{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of multioutput model using the functional API - Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset and standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "BL1j8CvLtF-2",
    "outputId": "8a78791e-9fcd-41cd-fc79-e2b6bf04cc5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "50.0 5.0\n"
     ]
    }
   ],
   "source": [
    "# Boston Housing dataset - load data\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(max(train_targets), min(train_targets))\n",
    "\n",
    "# standardize the data\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create, train and estimate the error of a model for the Housing dataset using the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FcRZweZhtYM5",
    "outputId": "c9f2ae1c-7a44-4472-db8d-9abef93d0979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 0s 769us/step - loss: 491.6964 - mae: 20.1852\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 774us/step - loss: 317.0489 - mae: 15.6194\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 589us/step - loss: 151.1702 - mae: 10.0212\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 608us/step - loss: 67.0741 - mae: 6.2745\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 495us/step - loss: 40.6380 - mae: 4.5751\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 451us/step - loss: 29.3454 - mae: 3.7709\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 441us/step - loss: 24.3879 - mae: 3.3757\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 20.9686 - mae: 3.1387\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 18.6246 - mae: 3.0119\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 16.6008 - mae: 2.7779\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 15.3623 - mae: 2.7328\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 905us/step - loss: 13.8552 - mae: 2.5981\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 818us/step - loss: 13.3025 - mae: 2.5561\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 12.4111 - mae: 2.5109\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 11.8433 - mae: 2.4243\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 11.2782 - mae: 2.4137\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 917us/step - loss: 11.0353 - mae: 2.3701\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 758us/step - loss: 10.7914 - mae: 2.3308\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 667us/step - loss: 10.3638 - mae: 2.3427\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 471us/step - loss: 10.1041 - mae: 2.2923\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 22.5045 - mae: 3.1777\n",
      "22.504518508911133 3.177690029144287\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# create model using functional API\n",
    "input_tensor = Input(shape=(train_data.shape[1],))\n",
    "x = layers.Dense(64, activation='relu')(input_tensor)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output_tensor = layers.Dense(1,activation= \"linear\")(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()\n",
    "\n",
    "# train and test\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.fit(train_data, train_targets, epochs=20, batch_size=16, verbose=1)\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "print(test_mse_score, test_mae_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a binary variable to transform the model to a multi-output problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsXgK6Xb3o08"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# In computational geometry, the bin is a data structure that allows efficient region queries. Each time a data point falls into a bin, the frequency of that bin is increased by one.\n",
    "# create binary variable by returning the indexes of the bin to which the value belongs.\n",
    "# where the bin is defined as 20 with a right as False, meaning it returns the price higher than 20\n",
    "train_targets_bin = np.digitize(train_targets,bins=[20])\n",
    "test_targets_bin = np.digitize(test_targets,bins=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "37eC1O3Jw9aP",
    "outputId": "5e5e794c-362b-45f9-f94f-f4a6b54a3cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           4160        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output1 (Dense)                 (None, 1)            65          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output2 (Dense)                 (None, 1)            65          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,186\n",
      "Trainable params: 5,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 26.5549 - output1_loss: 517.3840 - output2_loss: 0.6857\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 827us/step - loss: 18.0171 - output1_loss: 349.8301 - output2_loss: 0.5256\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 9.2024 - output1_loss: 175.6437 - output2_loss: 0.4202\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 862us/step - loss: 4.1389 - output1_loss: 75.2044 - output2_loss: 0.3787\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.5115 - output1_loss: 43.0284 - output2_loss: 0.3601\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.7847 - output1_loss: 28.8200 - output2_loss: 0.3437\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.4663 - output1_loss: 22.7804 - output2_loss: 0.3273\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3351 - output1_loss: 20.5275 - output2_loss: 0.3087\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 928us/step - loss: 1.1949 - output1_loss: 17.9613 - output2_loss: 0.2968\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 836us/step - loss: 1.1288 - output1_loss: 16.8552 - output2_loss: 0.2861\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.0521 - output1_loss: 15.5401 - output2_loss: 0.2751\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9971 - output1_loss: 14.5695 - output2_loss: 0.2687\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9337 - output1_loss: 13.6390 - output2_loss: 0.2517\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 941us/step - loss: 0.9148 - output1_loss: 13.2760 - output2_loss: 0.2510\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 899us/step - loss: 0.8529 - output1_loss: 12.4321 - output2_loss: 0.2313\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 617us/step - loss: 0.8284 - output1_loss: 12.0202 - output2_loss: 0.2274\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 535us/step - loss: 0.8144 - output1_loss: 11.8080 - output2_loss: 0.2240\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 525us/step - loss: 0.7808 - output1_loss: 11.2183 - output2_loss: 0.2199\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7555 - output1_loss: 10.8364 - output2_loss: 0.2137\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.7359 - output1_loss: 10.5906 - output2_loss: 0.2064\n",
      "4/4 [==============================] - 0s 678us/step - loss: 1.5943 - output1_loss: 25.2966 - output2_loss: 0.3295\n",
      "[1.5943026542663574, 25.29659080505371, 0.329473078250885]\n"
     ]
    }
   ],
   "source": [
    "# model with two different outputs: regression and binary classification\n",
    "\n",
    "input_tensor = Input(shape=(train_data.shape[1],))\n",
    "x = layers.Dense(64, activation='relu')(input_tensor)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output_tensor1 = layers.Dense(1,activation= \"linear\", name= \"output1\")(x)\n",
    "output_tensor2 = layers.Dense(1,activation= \"sigmoid\", name = \"output2\")(x)\n",
    "\n",
    "model = Model(input_tensor, [output_tensor1, output_tensor2])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=['mse','binary_crossentropy'], loss_weights = [0.05, 1])\n",
    "# define the weights for the loss function of each exit\n",
    "\n",
    "model.fit(train_data, [train_targets, train_targets_bin], epochs=20, batch_size=16)\n",
    "\n",
    "print(model.evaluate(test_data, [test_targets, test_targets_bin]) )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ex_functionalapi_housing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
