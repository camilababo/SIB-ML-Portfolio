{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons (feedforward NN) examples in scikit-learn\n",
    "\"A multilayer perceptron (MLP) is a fully connected class of feedforward artificial neural network (ANN). The term MLP is used ambiguously, sometimes loosely to mean any feedforward ANN, sometimes strictly to refer to networks composed of multiple layers of perceptrons (with threshold activation). An MLP consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo XNOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Regarding solvers:\n",
    "# The solver hyperparameter is the solver for weight optimization.\n",
    "# 'lbfgs' is an optimizer in the family of quasi-Newton methods).\n",
    "# The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Regarding hidden layers:\n",
    "# When a number lower than 5 is used the local optimization function can get stuck at a local minimum. So 5 is generally used as a minimum for the hidden layers so the model can arrive at the best value for the cost function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n",
    "y = [1, 0, 0, 1]\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5,))\n",
    "\n",
    "mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dig = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(50,20))\n",
    "# hidden layer sizes: 20 layers with 50 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9271200866604767\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(mlp_dig, digits.data, digits.target, cv = 5)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Score with scaled data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9293423088826989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(digits.data)\n",
    "scaled_digits = scaler.transform(digits.data)    \n",
    "scores = cross_val_score(mlp_dig, scaled_digits, digits.target, cv = 5)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression example (Diabetes dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47702096367100644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "mlp_diab = MLPRegressor(solver = \"sgd\", hidden_layer_sizes=(30,), max_iter = 2000)\n",
    "# solver: ‘sgd’ refers to stochastic gradient descent.\n",
    "# hidden layer sizes: 1 layer with 30 units.\n",
    "\n",
    "scores = cross_val_score(mlp_diab, diabetes.data, diabetes.target, cv = 5)\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
