{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceitos e modelos complementares/ avançados de machine learning - exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar os datasets e pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(iris.data))\n",
    "iris_X_train = iris.data[indices[:-10]]\n",
    "iris_y_train = iris.target[indices[:-10]]\n",
    "iris_X_test = iris.data[indices[-10:]]\n",
    "iris_y_test = iris.target[indices[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diab_X_train = diabetes.data[:-20]\n",
    "diab_X_test = diabetes.data[-20:]\n",
    "diab_y_train = diabetes.target[:-20]\n",
    "diab_y_test = diabetes.target[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "iris_scaler = StandardScaler()\n",
    "iris_scaler.fit(iris_X_train)\n",
    "iris_sc_X_train = iris_scaler.transform(iris_X_train)\n",
    "iris_sc_X_test = iris_scaler.transform(iris_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "Valores previstos:  [1 1 1 0 0 0 1 0 1 1]\n",
      "Valores reais:  [1 1 1 0 0 0 2 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_iris = svm.SVC()\n",
    "svm_iris = svm_iris.fit(iris_sc_X_train, iris_y_train)\n",
    "print(svm_iris)\n",
    "\n",
    "print(\"Valores previstos: \" , svm_iris.predict(iris_sc_X_test))\n",
    "print(\"Valores reais: \" , iris_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100.0, gamma=0.001)\n",
      "[8]\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 300x300 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "trData_inp = digits.data[:-1]\n",
    "trData_out = digits.target[:-1]\n",
    "\n",
    "svm_model = clf.fit(trData_inp, trData_out)\n",
    "print(svm_model)\n",
    "print(clf.predict([digits.data[-1]]))\n",
    "print(digits.target[-1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r,           \n",
    " interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=100, kernel='linear')\n",
      "Valores previstos:  [179.61688462 155.31948765 163.87979529  99.89228562 170.28805378\n",
      " 131.26705002 238.18996896 105.01915047 121.79481057 125.6153453\n",
      " 201.04012415  76.71684848 134.10267481 120.75660548  65.2386807\n",
      " 180.30838636 121.13053915 132.57267099 184.18332192  64.77129549]\n",
      "Valores reais:  [233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.  49.  64.\n",
      "  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regr_svm = SVR(kernel = \"linear\", C = 100)\n",
    "regr_svm = regr_svm.fit(diab_X_train, diab_y_train)\n",
    "print(regr_svm)\n",
    "pred_diab = regr_svm.predict(diab_X_test)\n",
    "print(\"Valores previstos: \" , pred_diab)\n",
    "print(\"Valores reais: \" , diab_y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimação do erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (105,)\n",
      "(45, 4) (45,)\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris.data, iris.target, test_size= 0.3)\n",
    "print(iris_X_train.shape, iris_y_train.shape)\n",
    "print(iris_X_test.shape, iris_y_test.shape)\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear', C=1)\n",
    "svm_model.fit(iris_X_train, iris_y_train)\n",
    "print(svm_model.score(iris_X_test, iris_y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# performs an internal dataset division\n",
    "# in a bigger dataset we should do a cross validation with the training dataset and the dev set\n",
    "scores = cross_val_score(svm_model, iris.data, iris.target, cv = 5)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "# returns an array of scores of the estimator for each run of the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcao scoring: F1\n",
      "[0.96658312 1.         0.96658312 0.96658312 1.        ]\n",
      "0.9799498746867169\n"
     ]
    }
   ],
   "source": [
    "print(\"Funcao scoring: F1\") # recall and precision\n",
    "scores_f1 = cross_val_score(svm_model, iris.data, y = iris.target, scoring = \"f1_weighted\", cv = 5)\n",
    "print(scores_f1)\n",
    "print(scores_f1.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo_cv = LeaveOneOut()\n",
    "scores_loo = cross_val_score(svm_model, iris.data, iris.target, cv=loo_cv)\n",
    "\n",
    "print(scores_loo.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14739157 0.12560632 0.18203832 0.12242227 0.15658497]\n",
      "0.14680869160894452\n"
     ]
    }
   ],
   "source": [
    "regr_model1 = SVR()\n",
    "scores_r2 = cross_val_score(regr_model1, diabetes.data, y = diabetes.target, scoring = \"r2\", cv = 5)\n",
    "print(scores_r2)\n",
    "print(scores_r2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00149033 -0.06183971  0.00870316 -0.03402398 -0.01126642]\n",
      "-0.01998345627927085\n"
     ]
    }
   ],
   "source": [
    "regr_model2 = SVR(kernel = \"linear\")\n",
    "scores_r2_2 = cross_val_score(regr_model2, diabetes.data, y = diabetes.target, scoring = \"r2\", cv = 5)\n",
    "print(scores_r2_2)\n",
    "print(scores_r2_2.mean())\n",
    "\n",
    "# the scores are negative because in sci-kit learn most score are maximized but for the ines that need to be minimized they are negated for the unified scoring API to work correctly\n",
    "# The score that is returned is therefore negated when it is a score that should be minimized and left positive if it is a score that should be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3852724  0.47720411 0.46589184 0.43556318 0.4737967 ]\n",
      "0.4475456436081261\n"
     ]
    }
   ],
   "source": [
    "regr_model3 = SVR(kernel = \"linear\", C = 100)\n",
    "scores_r2_3 = cross_val_score(regr_model3, diabetes.data, y = diabetes.target, scoring = \"r2\", cv = 5)\n",
    "print(scores_r2_3)\n",
    "print(scores_r2_3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2995.7298614  -3316.84367117 -3342.76112605 -2961.18687133\n",
      " -3404.90910444]\n",
      "[-44.31923611 -45.48879312 -49.78601984 -44.36915568 -47.95286224]\n"
     ]
    }
   ],
   "source": [
    "scores_mse = cross_val_score(estimator = regr_model3, X= diabetes.data, y= diabetes.target, scoring= \"neg_mean_squared_error\", cv= 5)\n",
    "print (scores_mse)\n",
    "scores_mad = cross_val_score(estimator = regr_model3, X= diabetes.data, scoring = \"neg_mean_absolute_error\", y= diabetes.target, cv= 5)\n",
    "print (scores_mad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media modelo RBF:  0.14214669660283727\n",
      "Desvio padrao modelo RBF: 0.02849308943037903\n",
      "Media modelo Linear:  0.44659792690858974\n",
      "Desvio padrao modelo Linear: 0.034434039871259314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits = 30, test_size=0.3)\n",
    "scores_ss1 = cross_val_score(regr_model1, diabetes.data, y = diabetes.target, scoring = \"r2\", cv = ss)\n",
    "print (\"Media modelo RBF: \", scores_ss1.mean())\n",
    "print (\"Desvio padrao modelo RBF:\", scores_ss1.std())\n",
    "\n",
    "scores_ss2 = cross_val_score(regr_model3, diabetes.data, y = diabetes.target, scoring = \"r2\", cv = ss)\n",
    "print (\"Media modelo Linear: \",scores_ss2.mean())\n",
    "print (\"Desvio padrao modelo Linear:\",scores_ss2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.93333333 0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "bagged_model = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "scores_bag = cross_val_score(bagged_model, iris.data, iris.target, cv = 5)\n",
    "print (scores_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.9        0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "bagged_model2 = BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "scores_bag2 = cross_val_score(bagged_model2, iris.data, iris.target, cv = 5)\n",
    "\n",
    "print(scores_bag2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.93333333 0.93333333 1.        ]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100) # 100 trees\n",
    "\n",
    "scores_rf = cross_val_score(rf_model, iris.data, iris.target, cv = 5)\n",
    "\n",
    "print (scores_rf)\n",
    "print (scores_rf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37290696 0.49168625 0.42324096 0.38168863 0.43826314]\n",
      "0.42155718783664753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regr = RandomForestRegressor()\n",
    "\n",
    "scores_rf2 = cross_val_score(rf_regr, diabetes.data, diabetes.target, cv = 5)\n",
    "\n",
    "print (scores_rf2)\n",
    "print (scores_rf2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exemplos com boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.93333333 0.93333333 0.9        1.        ]\n",
      "0.9466666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_tree = AdaBoostClassifier(n_estimators=100) # how many models\n",
    "# the classifier isn't defined but the default is trees\n",
    "\n",
    "scores_ada = cross_val_score(ada_tree, iris.data, iris.target, cv = 5)\n",
    "\n",
    "print (scores_ada)\n",
    "print (scores_ada.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36594331 0.48072389 0.41495176 0.37080144 0.3821784 ]\n",
      "0.40291976110743627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada_reg = AdaBoostRegressor(n_estimators=100)\n",
    "\n",
    "scores_ada_reg = cross_val_score(ada_reg, diabetes.data, diabetes.target, cv = 5)\n",
    "\n",
    "print (scores_ada_reg)\n",
    "print (scores_ada_reg.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2383.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anaca\\Documents\\GitHub\\SIB-ML-Portfolio\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:294: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36870486 0.49537179 0.39126583 0.32586461 0.40404568]\n",
      "0.39705055456003246\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "clf.fit(diab_X_train, diab_y_train)\n",
    "mse = mean_squared_error(diab_y_test, clf.predict(diab_X_test))\n",
    "print(\"MSE: %.1f\" % mse)\n",
    "\n",
    "scores_r2 = cross_val_score(estimator = clf, X= diabetes.data, scoring = \"r2\", y = diabetes.target)\n",
    "print(scores_r2)\n",
    "print(scores_r2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voting classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accur.: 0.96 (std 0.04) [Logistic]\n",
      "Accur.: 0.97 (std 0.02) [RF]\n",
      "Accur.: 0.95 (std 0.03) [NB]\n",
      "Accur.: 0.95 (std 0.03) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "## classificadores distintos; votação simples\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "iris_scaler = StandardScaler()\n",
    "iris_scaler.fit(iris.data)\n",
    "iris_sc = iris_scaler.transform(iris.data)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic', \"RF\", \"NB\", 'Ensemble']):\n",
    "    scores = cross_val_score(clf, iris_sc, iris.target, cv=5, scoring='accuracy')\n",
    "    print(\"Accur.: %0.2f (std %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "## classificadores distintos; votação com pesos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_sc, iris.target, test_size= 0.3)\n",
    "\n",
    "clf4 = DecisionTreeClassifier(max_depth=4)\n",
    "clf5 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf6 = SVC(gamma='scale', kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(estimators=[('dt', clf4), ('knn', clf5), ('svc', clf6)], voting='soft', weights=[1, 2, 3])\n",
    "# soft voting with wight 1 for the decision tree, weight 2 to the knn and weight 3 to the support vector machine\n",
    "\n",
    "eclf = eclf.fit(iris_X_train, iris_y_train)\n",
    "print(eclf.score(iris_X_test, iris_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtros por variabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 53)\n"
     ]
    }
   ],
   "source": [
    "# filtrar features constantes\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sel_const = VarianceThreshold(threshold=0.1)\n",
    "digits_no_const = sel_const.fit_transform(digits.data)\n",
    "\n",
    "print(digits.data.shape)\n",
    "print (digits_no_const.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9810738671632526\n",
      "0.9810738671632526\n"
     ]
    }
   ],
   "source": [
    "svm_mod = svm.SVC(gamma=0.001, C=100.)\n",
    "\n",
    "\n",
    "scores= cross_val_score(svm_mod, digits.data, digits.target, cv= 10)\n",
    "print (scores.mean())\n",
    "\n",
    "scores_vt= cross_val_score(svm_mod, digits_no_const, digits.target, cv= 10)\n",
    "print (scores_vt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 29)\n",
      "0.9777405338299193\n"
     ]
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=20)\n",
    "filt = sel.fit_transform(digits.data)\n",
    "\n",
    "print (filt.shape)\n",
    "\n",
    "scores_vt= cross_val_score(svm_mod, filt, digits.target, cv= 10)\n",
    "print (scores_vt.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtros por análise estatística univariada (aplicada a cada variável independenten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9721818746120421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "filt_kb = SelectKBest(chi2, k=30).fit_transform(digits_no_const, digits.target)\n",
    "scores_kb = cross_val_score(svm_mod, filt_kb, digits.target, cv = 10)\n",
    "print (scores_kb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738578522656735\n"
     ]
    }
   ],
   "source": [
    "filt_kb2 = SelectKBest(f_classif, k=30).fit_transform(digits_no_const, digits.target)\n",
    "scores_kb2 = cross_val_score(svm_mod, filt_kb2, digits.target, cv = 10)\n",
    "print (scores_kb2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrapper: recursive feature elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946576660459342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "svm_model = svm.SVC(kernel = \"linear\", C=100.)\n",
    "\n",
    "rfe = RFE(estimator=svm_model, n_features_to_select=30, step=2)\n",
    "\n",
    "scores_rfe = cross_val_score(rfe, digits_no_const, digits.target, cv = 10)\n",
    "print (scores_rfe.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Procura em grelha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, gamma=0.001)\n",
      "0.972185082017951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 3, 10, 100], 'gamma':[0.01, 0.001]}\n",
    "svm_model_d = svm.SVC( )\n",
    "\n",
    "opt_model_d = GridSearchCV(svm_model_d, parameters, cv = 5)\n",
    "opt_model_d.fit(digits.data, digits.target)\n",
    "print (opt_model_d.best_estimator_)\n",
    "scores_gs = cross_val_score(opt_model_d, digits.data,  digits.target, cv = 5)\n",
    "print (scores_gs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Procura aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=30, gamma=0.001)\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.972 (std: 0.013)\n",
      "Parameters: {'kernel': 'rbf', 'gamma': 0.001, 'C': 30}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.972 (std: 0.013)\n",
      "Parameters: {'kernel': 'rbf', 'gamma': 0.001, 'C': 10}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.972 (std: 0.013)\n",
      "Parameters: {'kernel': 'rbf', 'gamma': 0.001, 'C': 3}\n",
      "\n",
      " 0.973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 0.5, 1, 3, 10, 30, 100, 1000], 'gamma':[0.1, 0.01, 0.05, 0.001]}\n",
    "\n",
    "\n",
    "rand_search = RandomizedSearchCV(svm_model_d, param_distributions=parameters, n_iter=20, cv = 5)\n",
    "\n",
    "rand_search.fit(digits.data, digits.target)\n",
    "\n",
    "print (rand_search.best_estimator_)\n",
    "report(rand_search.cv_results_)\n",
    "\n",
    "scores_rs = cross_val_score(rand_search, digits.data, digits.target, cv = 5)\n",
    "print (\"% .3f\" %scores_rs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, max_features=4, min_samples_leaf=2)\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.940 (std: 0.018)\n",
      "Parameters: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 4, 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.938 (std: 0.022)\n",
      "Parameters: {'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 4, 'max_depth': None, 'criterion': 'gini', 'bootstrap': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.933 (std: 0.019)\n",
      "Parameters: {'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 4, 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
      "\n",
      " 0.940\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "param_dist = {\"max_depth\": [2, 3, None], \"max_features\": [2,4,6], \"min_samples_split\": [2,4,6],\n",
    "              \"min_samples_leaf\": [2,4,6], \"bootstrap\": [True, False], \"criterion\": [\"gini\", \"entropy\"]}\n",
    "# bootstraping -> resampling\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=20, cv = 5)\n",
    "\n",
    "rand_search.fit(digits.data, digits.target)\n",
    "\n",
    "print (rand_search.best_estimator_)\n",
    "report(rand_search.cv_results_)\n",
    "\n",
    "scores_rs = cross_val_score(rand_search, digits.data, digits.target, cv = 5)\n",
    "print (\"% .3f\" %scores_rs.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
